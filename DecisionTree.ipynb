{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf5041d-e6f7-46a0-b4ef-10ead11f5dfc",
   "metadata": {},
   "source": [
    "1. Реализовать класс DecisionTree. \n",
    "В классе **должны** быть методы\n",
    "```python\n",
    "def __init__(..., classification:bool=true, ...):\n",
    "    # some code\n",
    "def predict(...):\n",
    "    # some code\n",
    "def fit(...):\n",
    "    # some code\n",
    "```\n",
    "2. Реализовать класс RandomForest. \n",
    "В классе **должны** быть методы\n",
    "```python\n",
    "def __init__(..., classification:bool=true, ...):\n",
    "    # some code\n",
    "def predict(...):\n",
    "    # some code\n",
    "def fit(...):\n",
    "    # some code\n",
    "```\n",
    "3. Реализовать класс GradientBoosting. \n",
    "В классе **должны** быть методы\n",
    "```python\n",
    "def __init__(..., classification:bool=true, ...):\n",
    "    # some code\n",
    "def predict(...):\n",
    "    # some code\n",
    "def fit(...):\n",
    "    # some code\n",
    "```\n",
    "\n",
    "4. Обучить модели каждого алгоритма на следующих датасетах (проводим мини-соревнование между ними):\n",
    "    * регрессия: https://www.kaggle.com/datasets/hmavrodiev/london-bike-sharing-dataset\n",
    "    * классификация: https://www.kaggle.com/datasets/pankrzysiu/cifar10-python\n",
    "\n",
    "5. Объяснить, почему алгоритм $A$ \"победил\", а почему алгоритм $B$ \"проиграл\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1246e1f-ca73-4603-8701-3c9037dde882",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58c9766-b9b6-4c9b-bba7-3f02615325e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth: int = 0,\n",
    "        max_depth: int = None,\n",
    "        classification: bool = True,\n",
    "    ):\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.is_leaf = False\n",
    "        self.predicted_class = None\n",
    "        self.classification = classification\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # reset split info each time we fit this node\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "\n",
    "        if y.unique().numel() == 1:\n",
    "            self.is_leaf = True\n",
    "            self.predicted_class = y[0].item()\n",
    "            return\n",
    "\n",
    "        if self.max_depth is not None and self.depth >= self.max_depth:\n",
    "            self.is_leaf = True\n",
    "            self.predicted_class = self._get_prediction_class(y)\n",
    "            return\n",
    "\n",
    "        if self.classification:\n",
    "            self._fit_classification(X, y)\n",
    "        else:\n",
    "            self._fit_regression(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        dtype = torch.long if self.classification else torch.float32\n",
    "\n",
    "        if self.is_leaf:\n",
    "            return torch.full((X.shape[0],), self.predicted_class, dtype=dtype)\n",
    "\n",
    "        left_mask = X[:, self.feature_index] <= self.threshold\n",
    "        right_mask = X[:, self.feature_index] > self.threshold\n",
    "\n",
    "        y_pred = torch.empty(X.shape[0], dtype=dtype)\n",
    "        # cast just in case, to be robust\n",
    "        y_pred[left_mask] = self.left.predict(X[left_mask]).to(dtype)\n",
    "        y_pred[right_mask] = self.right.predict(X[right_mask]).to(dtype)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def _fit_classification(self, X, y):\n",
    "        (\n",
    "            self.feature_index,\n",
    "            self.threshold,\n",
    "            best_left_mask,\n",
    "            best_right_mask,\n",
    "        ) = self._find_best_split(X, y, self._gini)\n",
    "\n",
    "        if self.feature_index is None:\n",
    "            self.is_leaf = True\n",
    "            self.predicted_class = self._get_prediction_class(y)\n",
    "            return\n",
    "\n",
    "        self.left = DecisionTree(\n",
    "            depth=self.depth + 1,\n",
    "            max_depth=self.max_depth,\n",
    "            classification=self.classification,\n",
    "        )\n",
    "        self.right = DecisionTree(\n",
    "            depth=self.depth + 1,\n",
    "            max_depth=self.max_depth,\n",
    "            classification=self.classification,\n",
    "        )\n",
    "\n",
    "        self.left.fit(X[best_left_mask], y[best_left_mask])\n",
    "        self.right.fit(X[best_right_mask], y[best_right_mask])\n",
    "\n",
    "    def _fit_regression(self, X, y):\n",
    "        (\n",
    "            self.feature_index,\n",
    "            self.threshold,\n",
    "            best_left_mask,\n",
    "            best_right_mask,\n",
    "        ) = self._find_best_split(X, y, self._mse)\n",
    "\n",
    "        if self.feature_index is None:\n",
    "            self.is_leaf = True\n",
    "            self.predicted_class = self._get_prediction_class(y)\n",
    "            return\n",
    "\n",
    "        self.left = DecisionTree(\n",
    "            depth=self.depth + 1,\n",
    "            max_depth=self.max_depth,\n",
    "            classification=self.classification,\n",
    "        )\n",
    "        self.right = DecisionTree(\n",
    "            depth=self.depth + 1,\n",
    "            max_depth=self.max_depth,\n",
    "            classification=self.classification,\n",
    "        )\n",
    "\n",
    "        self.left.fit(X[best_left_mask], y[best_left_mask])\n",
    "        self.right.fit(X[best_right_mask], y[best_right_mask])\n",
    "\n",
    "    def _find_best_split(self, X, y, criterion_fn):\n",
    "        \"\"\"\n",
    "        Generic split search:\n",
    "        - criterion_fn(y_left, y_right) -> float (lower is better)\n",
    "        \"\"\"\n",
    "        num_features = X.shape[1]\n",
    "        best_score = float(\"inf\")\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_left_mask = None\n",
    "        best_right_mask = None\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            thresholds = torch.unique(X[:, feature])\n",
    "\n",
    "            for ts in thresholds:\n",
    "                left_mask = X[:, feature] <= ts\n",
    "                right_mask = X[:, feature] > ts\n",
    "\n",
    "                # skip degenerate splits\n",
    "                if not left_mask.any() or not right_mask.any():\n",
    "                    continue\n",
    "\n",
    "                y_left = y[left_mask]\n",
    "                y_right = y[right_mask]\n",
    "\n",
    "                score = criterion_fn(y_left, y_right)\n",
    "\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "                    best_threshold = ts.item()\n",
    "                    best_left_mask = left_mask\n",
    "                    best_right_mask = right_mask\n",
    "\n",
    "        return best_feature, best_threshold, best_left_mask, best_right_mask\n",
    "\n",
    "\n",
    "    def _get_prediction_class(self, y):\n",
    "        if self.classification:\n",
    "            return y.mode()[0].item()\n",
    "        return y.float().mean().item()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _gini_impurity(group):\n",
    "        if group.numel() == 0:\n",
    "            return 0.0\n",
    "        _, counts = torch.unique(group, return_counts=True)\n",
    "        probs = counts.float() / counts.sum()\n",
    "        return 1.0 - torch.sum(probs ** 2).item()\n",
    "\n",
    "    def _gini(self, y_left, y_right):\n",
    "        total_samples = y_left.numel() + y_right.numel()\n",
    "        gini_left = self._gini_impurity(y_left)\n",
    "        gini_right = self._gini_impurity(y_right)\n",
    "\n",
    "        return (\n",
    "            (y_left.numel() / total_samples) * gini_left\n",
    "            + (y_right.numel() / total_samples) * gini_right\n",
    "        )\n",
    "\n",
    "    def _mse(self, y_left, y_right):\n",
    "        total_samples = y_left.numel() + y_right.numel()\n",
    "        if total_samples == 0:\n",
    "            return 0.0\n",
    "\n",
    "        y_left_f = y_left.float()\n",
    "        y_right_f = y_right.float()\n",
    "\n",
    "        mse_left = (y_left_f - y_left_f.mean()).pow(2).mean().item()\n",
    "        mse_right = (y_right_f - y_right_f.mean()).pow(2).mean().item()\n",
    "\n",
    "        return (\n",
    "            (y_left.numel() / total_samples) * mse_left\n",
    "            + (y_right.numel() / total_samples) * mse_right\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75fc77-a917-4f42-87f8-6eac477bbc93",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781251a7-9f8e-4f4b-8e92-19e7c17b6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"london_merged.csv\")\n",
    "data.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "X, y = data.drop(columns=['cnt']).values, data.cnt.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51cfdb6-c2eb-48bf-a016-7c780de05c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np_reg, X_test_np_reg, y_train_np_reg, y_test_np_reg = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca8f88d-b71c-4859-8110-927ba112956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg = torch.tensor(X_train_np_reg, dtype=torch.float32)\n",
    "X_test_reg = torch.tensor(X_test_np_reg, dtype=torch.float32)\n",
    "y_train_reg = torch.tensor(y_train_np_reg, dtype=torch.float32)\n",
    "y_test_reg = torch.tensor(y_test_np_reg, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae22e92a-5745-47b6-947b-8decc5257c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 10\n",
    "dt = DecisionTree(max_depth=max_depth, classification=False)\n",
    "\n",
    "dt.fit(X_train_reg, y_train_reg)\n",
    "y_train_pred = dt.predict(X_train_reg)\n",
    "y_test_pred = dt.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf12e0cd-eedf-4a3f-a60f-7423e7868b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe1c4bc-4f08-4c6e-8e5a-2cc45329596d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric r2_score\n",
      "Train 0.46523517370224\n",
      "Test 0.20781952142715454\n",
      "\n",
      "Metric mean_absolute_error\n",
      "Train 545.825927734375\n",
      "Test 683.1919555664062\n",
      "\n",
      "Metric mean_absolute_percentage_error\n",
      "Train 200039410434048.0\n",
      "Test 2.636504650115967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in [r2_score, mean_absolute_error, mean_absolute_percentage_error]:\n",
    "    print(f'Metric {m.__name__}')\n",
    "    print(f'Train {m(y_train_np_reg, y_train_pred)}')\n",
    "    print(f'Test {m(y_test_np_reg, y_test_pred)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9613f922-b72a-4df3-866a-005bc9293bd4",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e0a6a8-503b-49ea-b194-57e3ab8bc173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4187d640-2fd8-4cbc-8e72-efa52b7831f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        d = pickle.load(fo, encoding='bytes')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a85df0-cdf0-4e90-84ce-058a87e1ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'cifar-10-batches-py'\n",
    "\n",
    "files = [os.path.join(base_dir, f) for f in os.listdir(base_dir) if '_batch_' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8144834a-3c41-446f-85fe-7a3456b62213",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [unpickle(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e516d838-3725-42db-b69b-da8538c448ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np_cl, y_train_np_cl = data[0][b'data'], data[0][b'labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a7ecebe-e4ad-435e-bbd4-671f1c51c24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fac5b3e-e0d9-4683-8e8a-027d5dab18dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = unpickle(os.path.join(base_dir, 'test_batch'))\n",
    "\n",
    "X_test_np_cl, y_test_np_cl = test_batch[b'data'], test_batch[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ac097b-c82c-4403-8401-acae664dfc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cl = torch.tensor(X_train_np_cl, dtype=torch.float32)\n",
    "X_test_cl = torch.tensor(X_test_np_cl, dtype=torch.float32)\n",
    "y_train_cl = torch.tensor(y_train_np_cl, dtype=torch.long)\n",
    "y_test_cl = torch.tensor(y_test_np_cl, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "834c3c06-98e8-419a-beb8-0b9a2e2fc44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m dt_cl = DecisionTree(\n\u001b[32m      2\u001b[39m     max_depth=\u001b[32m1\u001b[39m,\n\u001b[32m      3\u001b[39m     classification=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mdt_cl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_cl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cl\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mDecisionTree.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classification:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_regression(X, y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mDecisionTree._fit_classification\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit_classification\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[32m     57\u001b[39m     (\n\u001b[32m     58\u001b[39m         \u001b[38;5;28mself\u001b[39m.feature_index,\n\u001b[32m     59\u001b[39m         \u001b[38;5;28mself\u001b[39m.threshold,\n\u001b[32m     60\u001b[39m         best_left_mask,\n\u001b[32m     61\u001b[39m         best_right_mask,\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_find_best_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gini\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     65\u001b[39m         \u001b[38;5;28mself\u001b[39m.is_leaf = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 136\u001b[39m, in \u001b[36mDecisionTree._find_best_split\u001b[39m\u001b[34m(self, X, y, criterion_fn)\u001b[39m\n\u001b[32m    133\u001b[39m y_left = y[left_mask]\n\u001b[32m    134\u001b[39m y_right = y[right_mask]\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m score = \u001b[43mcriterion_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score < best_score:\n\u001b[32m    139\u001b[39m     best_score = score\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 161\u001b[39m, in \u001b[36mDecisionTree._gini\u001b[39m\u001b[34m(self, y_left, y_right)\u001b[39m\n\u001b[32m    158\u001b[39m     probs = counts.float() / counts.sum()\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1.0\u001b[39m - torch.sum(probs ** \u001b[32m2\u001b[39m).item()\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_gini\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_left, y_right):\n\u001b[32m    162\u001b[39m     total_samples = y_left.numel() + y_right.numel()\n\u001b[32m    163\u001b[39m     gini_left = \u001b[38;5;28mself\u001b[39m._gini_impurity(y_left)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3413\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3409\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3411\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3413\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3414\u001b[39m     )\n\u001b[32m   3416\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3467\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3464\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3465\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3466\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3467\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3469\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3470\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3471\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3472\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/ultratb.py:1188\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1187\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/ultratb.py:1059\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1056\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1058\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1059\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1063\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1065\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1066\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1074\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1075\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/ultratb.py:867\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    860\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    865\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    866\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    871\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    872\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/ultratb.py:779\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    769\u001b[39m         frames.append(\n\u001b[32m    770\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    771\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    776\u001b[39m             )\n\u001b[32m    777\u001b[39m         )\n\u001b[32m    778\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    781\u001b[39m     frames.append(\n\u001b[32m    782\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    783\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/ultratb.py:654\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    651\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    653\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     \u001b[43m_format_traceback_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheme_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theme_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlvals_toks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m )\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/IPython/core/tbtools.py:99\u001b[39m, in \u001b[36m_format_traceback_lines\u001b[39m\u001b[34m(lines, theme, has_colors, lvals_toks)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     98\u001b[39m lineno = stack_line.lineno\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m line = \u001b[43mstack_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygmented\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m)\u001b[49m.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack_line.is_current:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# This is the line with the error\u001b[39;00m\n\u001b[32m    102\u001b[39m     pad = numbers_width - \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(lineno))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/stack_data/core.py:391\u001b[39m, in \u001b[36mLine.render\u001b[39m\u001b[34m(self, markers, strip_leading_indent, pygmented, escape_html)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pygmented \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frame_info.scope:\n\u001b[32m    390\u001b[39m     assert_(\u001b[38;5;129;01mnot\u001b[39;00m markers, \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot use pygmented with markers\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     start_line, lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pygmented_scope_lines\u001b[49m\n\u001b[32m    392\u001b[39m     result = lines[\u001b[38;5;28mself\u001b[39m.lineno - start_line]\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strip_leading_indent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/stack_data/core.py:824\u001b[39m, in \u001b[36mFrameInfo._pygmented_scope_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     ranges = []\n\u001b[32m    823\u001b[39m code = atext.get_text(scope)\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m lines = \u001b[43m_pygmented_with_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m start_line = \u001b[38;5;28mself\u001b[39m.source.line_range(scope)[\u001b[32m0\u001b[39m]\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_line, lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/stack_data/utils.py:166\u001b[39m, in \u001b[36m_pygmented_with_ranges\u001b[39m\u001b[34m(formatter, code, ranges)\u001b[39m\n\u001b[32m    164\u001b[39m lexer = MyLexer(stripnl=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     highlighted = \u001b[43mpygments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# When pygments fails, prefer code without highlighting over crashing\u001b[39;00m\n\u001b[32m    169\u001b[39m     highlighted = code\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/pygments/__init__.py:82\u001b[39m, in \u001b[36mhighlight\u001b[39m\u001b[34m(code, lexer, formatter, outfile)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhighlight\u001b[39m(code, lexer, formatter, outfile=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     78\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    This is the most high-level highlighting function. It combines `lex` and\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    `format` in one function.\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/pygments/__init__.py:64\u001b[39m, in \u001b[36mformat\u001b[39m\u001b[34m(tokens, formatter, outfile)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outfile:\n\u001b[32m     63\u001b[39m     realoutfile = \u001b[38;5;28mgetattr\u001b[39m(formatter, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m BytesIO() \u001b[38;5;129;01mor\u001b[39;00m StringIO()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealoutfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m realoutfile.getvalue()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/pygments/formatters/terminal256.py:250\u001b[39m, in \u001b[36mTerminal256Formatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokensource, outfile):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokensource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/pygments/formatter.py:124\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# wrap the outfile in a StreamWriter\u001b[39;00m\n\u001b[32m    123\u001b[39m     outfile = codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding)[\u001b[32m3\u001b[39m](outfile)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_unencoded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokensource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/pygments/formatters/terminal256.py:256\u001b[39m, in \u001b[36mTerminal256Formatter.format_unencoded\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.linenos:\n\u001b[32m    254\u001b[39m     \u001b[38;5;28mself\u001b[39m._write_lineno(outfile)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtokensource\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnot_found\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnot_found\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/stack_data/utils.py:158\u001b[39m, in \u001b[36m_pygmented_with_ranges.<locals>.MyLexer.get_tokens\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[32m    157\u001b[39m     length = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m            \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExecutingNode\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/pygments/lexer.py:270\u001b[39m, in \u001b[36mLexer.get_tokens.<locals>.streamer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstreamer\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_tokens_unprocessed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/ais/lib/python3.12/site-packages/pygments/lexer.py:712\u001b[39m, in \u001b[36mRegexLexer.get_tokens_unprocessed\u001b[39m\u001b[34m(self, text, stack)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[32m1\u001b[39m:\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m rexmatch, action, new_state \u001b[38;5;129;01min\u001b[39;00m statetokens:\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m         m = \u001b[43mrexmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m m:\n\u001b[32m    714\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dt_cl = DecisionTree(\n",
    "    max_depth=1,\n",
    "    classification=True,\n",
    ")\n",
    "\n",
    "print(\"--------\")\n",
    "\n",
    "dt_cl.fit(\n",
    "    X_train_cl, y_train_cl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407bb2cb-bb25-4c20-a2b3-b828c4342062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, roc_auc_score, precision_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b6e63-7884-43a4-b236-f78e8e89da0b",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38e1899c-5bae-4d96-bca0-72c5999eecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators: int = 100,\n",
    "        max_depth: int = None,\n",
    "        max_features = None,\n",
    "        bootstrap: bool = True,\n",
    "        classification: bool = True,\n",
    "        random_state: int | None = None,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.classification = classification\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.features_per_tree = []\n",
    "\n",
    "    def _get_n_sub_features(self, n_features: int) -> int:\n",
    "        if self.max_features is None:\n",
    "            if self.classification:\n",
    "                k = int(np.sqrt(n_features))\n",
    "            else:\n",
    "                k = n_features\n",
    "        elif isinstance(self.max_features, float):\n",
    "            k = int(self.max_features * n_features)\n",
    "        else:\n",
    "            k = int(self.max_features)\n",
    "        k = max(1, k)\n",
    "        k = min(n_features, k)\n",
    "        return k\n",
    "\n",
    "    def fit(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        if self.random_state is not None:\n",
    "            torch.manual_seed(self.random_state)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        n_sub_features = self._get_n_sub_features(n_features)\n",
    "\n",
    "        self.trees = []\n",
    "        self.features_per_tree = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                indices = torch.randint(0, n_samples, (n_samples,))\n",
    "            else:\n",
    "                indices = torch.randperm(n_samples)\n",
    "\n",
    "            X_sample = X[indices]\n",
    "            y_sample = y[indices]\n",
    "\n",
    "            feature_indices = torch.randperm(n_features)[:n_sub_features]\n",
    "            X_sample_sub = X_sample[:, feature_indices]\n",
    "\n",
    "            tree = DecisionTree(\n",
    "                max_depth=self.max_depth,\n",
    "                classification=self.classification,\n",
    "            )\n",
    "            tree.fit(X_sample_sub, y_sample)\n",
    "\n",
    "            self.trees.append(tree)\n",
    "            self.features_per_tree.append(feature_indices)\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        if len(self.trees) == 0:\n",
    "            raise RuntimeError(\"RandomForest has not been fitted yet.\")\n",
    "\n",
    "        all_preds = []\n",
    "        for tree, feature_indices in zip(self.trees, self.features_per_tree):\n",
    "            X_sub = X[:, feature_indices]\n",
    "            preds = tree.predict(X_sub)\n",
    "            all_preds.append(preds)\n",
    "\n",
    "        preds_stack = torch.stack(all_preds, dim=0)\n",
    "\n",
    "        if self.classification:\n",
    "            values, _ = torch.mode(preds_stack, dim=0)\n",
    "            return values\n",
    "\n",
    "        return preds_stack.float().mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc3e1727-08af-4359-8aec-353dce2bccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForest(\n",
    "    n_estimators=50,\n",
    "    max_depth=5,\n",
    "    classification=False,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_reg.fit(X_train_reg, y_train_reg)\n",
    "y_train_pred = rf_reg.predict(X_train_reg)\n",
    "y_test_pred = rf_reg.predict(X_test_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73c475eb-ca66-4c69-ab25-1329a4551ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric r2_score\n",
      "Train 0.3291732668876648\n",
      "Test 0.29936695098876953\n",
      "\n",
      "Metric mean_absolute_error\n",
      "Train 648.1138916015625\n",
      "Test 667.697265625\n",
      "\n",
      "Metric mean_absolute_percentage_error\n",
      "Train 196550588366848.0\n",
      "Test 2.867757797241211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in [r2_score, mean_absolute_error, mean_absolute_percentage_error]:\n",
    "    print(f'Metric {m.__name__}')\n",
    "    print(f'Train {m(y_train_np_reg, y_train_pred)}')\n",
    "    print(f'Test {m(y_test_np_reg, y_test_pred)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596792d-c4ee-4f7c-bf68-59461d51af46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "812e3dfe-34f3-4086-bf57-7315e014eba5",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c7f24c4-9f3a-45b8-a560-e1924b9c1dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators: int = 100,\n",
    "        learning_rate: float = 0.1,\n",
    "        max_depth: int = 3,\n",
    "        classification: bool = True,\n",
    "        random_state: int = None,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.classification = classification\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.init_prediction = 0.0\n",
    "\n",
    "    def fit(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        if self.random_state is not None:\n",
    "            torch.manual_seed(self.random_state)\n",
    "\n",
    "        self.trees = []\n",
    "\n",
    "        if self.classification:\n",
    "            y_float = y.float()\n",
    "            unique = torch.unique(y)\n",
    "            if unique.numel() != 2:\n",
    "                raise NotImplementedError(\"Only binary classification is supported\")\n",
    "            p = y_float.mean()\n",
    "            eps = 1e-6\n",
    "            p = torch.clamp(p, eps, 1 - eps)\n",
    "            self.init_prediction = torch.log(p / (1 - p)).item()\n",
    "            F = torch.full_like(y_float, self.init_prediction, dtype=torch.float32)\n",
    "            for _ in range(self.n_estimators):\n",
    "                p_hat = torch.sigmoid(F)\n",
    "                residuals = y_float - p_hat\n",
    "                tree = DecisionTree(\n",
    "                    max_depth=self.max_depth,\n",
    "                    classification=False,\n",
    "                )\n",
    "                tree.fit(X, residuals)\n",
    "                update = tree.predict(X).float()\n",
    "                F = F + self.learning_rate * update\n",
    "                self.trees.append(tree)\n",
    "        else:\n",
    "            y_float = y.float()\n",
    "            self.init_prediction = y_float.mean().item()\n",
    "            F = torch.full_like(y_float, self.init_prediction, dtype=torch.float32)\n",
    "            for _ in range(self.n_estimators):\n",
    "                residuals = y_float - F\n",
    "                tree = DecisionTree(\n",
    "                    max_depth=self.max_depth,\n",
    "                    classification=False,\n",
    "                )\n",
    "                tree.fit(X, residuals)\n",
    "                update = tree.predict(X).float()\n",
    "                F = F + self.learning_rate * update\n",
    "                self.trees.append(tree)\n",
    "\n",
    "    def _raw_predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        if len(self.trees) == 0:\n",
    "            raise RuntimeError(\"GradientBoosting has not been fitted yet.\")\n",
    "        n_samples = X.shape[0]\n",
    "        F = torch.full((n_samples,), self.init_prediction, dtype=torch.float32)\n",
    "        for tree in self.trees:\n",
    "            F = F + self.learning_rate * tree.predict(X).float()\n",
    "        return F\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        F = self._raw_predict(X)\n",
    "        if self.classification:\n",
    "            proba_pos = torch.sigmoid(F)\n",
    "            return (proba_pos >= 0.5).long()\n",
    "        return F\n",
    "\n",
    "    def predict_proba(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.classification:\n",
    "            raise RuntimeError(\"predict_proba is only available for classification.\")\n",
    "        F = self._raw_predict(X)\n",
    "        proba_pos = torch.sigmoid(F)\n",
    "        proba_neg = 1.0 - proba_pos\n",
    "        return torch.stack([proba_neg, proba_pos], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a8e7d-9dfd-4b99-9781-cd0f3d665302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ais",
   "language": "python",
   "name": "ais"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
