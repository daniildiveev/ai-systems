{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba59689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e3bb5",
   "metadata": {},
   "source": [
    "## Helper functions: CIFAR-10 loading with max pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7041ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file_path: str):\n",
    "    with open(file_path, \"rb\") as fo:\n",
    "        d = pickle.load(fo, encoding=\"bytes\")\n",
    "    return d\n",
    "\n",
    "def load_cifar10_with_maxpool(base_dir: str, pool_times: int = 2):\n",
    "    batch_files = [f for f in os.listdir(base_dir) if \"data_batch\" in f]\n",
    "    batch_files = sorted(batch_files)\n",
    "    train_batches = [unpickle(os.path.join(base_dir, f)) for f in batch_files]\n",
    "    test_batch = unpickle(os.path.join(base_dir, \"test_batch\"))\n",
    "\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    for batch in train_batches:\n",
    "        X_batch = torch.tensor(batch[b\"data\"], dtype=torch.float32)\n",
    "        y_batch = torch.tensor(batch[b\"labels\"], dtype=torch.long)\n",
    "        X_train_list.append(X_batch)\n",
    "        y_train_list.append(y_batch)\n",
    "    X_train = torch.cat(X_train_list, dim=0)\n",
    "    y_train = torch.cat(y_train_list, dim=0)\n",
    "\n",
    "    X_test = torch.tensor(test_batch[b\"data\"], dtype=torch.float32)\n",
    "    y_test = torch.tensor(test_batch[b\"labels\"], dtype=torch.long)\n",
    "\n",
    "    X_train = X_train.view(-1, 3, 32, 32) / 255.0\n",
    "    X_test = X_test.view(-1, 3, 32, 32) / 255.0\n",
    "\n",
    "    for _ in range(pool_times):\n",
    "        X_train = F.max_pool2d(X_train, kernel_size=2)\n",
    "        X_test = F.max_pool2d(X_test, kernel_size=2)\n",
    "\n",
    "    X_train_flat = X_train.view(X_train.size(0), -1)\n",
    "    X_test_flat = X_test.view(X_test.size(0), -1)\n",
    "\n",
    "    return X_train_flat, y_train, X_test_flat, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e35975",
   "metadata": {},
   "source": [
    "## Decision Tree implementation (classification and regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c4efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth: int = 0,\n",
    "        max_depth: int = None,\n",
    "        classification: bool = True,\n",
    "    ):\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.is_leaf = False\n",
    "        self.predicted_value = None\n",
    "        self.classification = classification\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "\n",
    "        if y.unique().numel() == 1:\n",
    "            self.is_leaf = True\n",
    "            self.predicted_value = y[0].item()\n",
    "            return\n",
    "\n",
    "        if self.max_depth is not None and self.depth >= self.max_depth:\n",
    "            self.is_leaf = True\n",
    "            self.predicted_value = self._get_prediction_value(y)\n",
    "            return\n",
    "\n",
    "        if self.classification:\n",
    "            self._fit_classification(X, y)\n",
    "        else:\n",
    "            self._fit_regression(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        dtype = torch.long if self.classification else torch.float32\n",
    "\n",
    "        if self.is_leaf:\n",
    "            return torch.full((X.shape[0],), self.predicted_value, dtype=dtype)\n",
    "\n",
    "        left_mask = X[:, self.feature_index] <= self.threshold\n",
    "        right_mask = X[:, self.feature_index] > self.threshold\n",
    "\n",
    "        y_pred = torch.empty(X.shape[0], dtype=dtype)\n",
    "        y_pred[left_mask] = self.left.predict(X[left_mask]).to(dtype)\n",
    "        y_pred[right_mask] = self.right.predict(X[right_mask]).to(dtype)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def _fit_classification(self, X, y):\n",
    "        (\n",
    "            self.feature_index,\n",
    "            self.threshold,\n",
    "            best_left_mask,\n",
    "            best_right_mask,\n",
    "        ) = self._find_best_split(X, y, self._gini)\n",
    "\n",
    "        if self.feature_index is None:\n",
    "            self.is_leaf = True\n",
    "            self.predicted_value = self._get_prediction_value(y)\n",
    "            return\n",
    "\n",
    "        self.left = DecisionTree(\n",
    "            depth=self.depth + 1,\n",
    "            max_depth=self.max_depth,\n",
    "            classification=self.classification,\n",
    "        )\n",
    "        self.right = DecisionTree(\n",
    "            depth=self.depth + 1,\n",
    "            max_depth=self.max_depth,\n",
    "            classification=self.classification,\n",
    "        )\n",
    "\n",
    "        self.left.fit(X[best_left_mask], y[best_left_mask])\n",
    "        self.right.fit(X[best_right_mask], y[best_right_mask])\n",
    "\n",
    "    def _fit_regression(self, X, y):\n",
    "        (\n",
    "            self.feature_index,\n",
    "            self.threshold,\n",
    "            best_left_mask,\n",
    "            best_right_mask,\n",
    "        ) = self._find_best_split(X, y, self._mse)\n",
    "\n",
    "        if self.feature_index is None:\n",
    "            self.is_leaf = True\n",
    "            self.predicted_value = self._get_prediction_value(y)\n",
    "            return\n",
    "\n",
    "        self.left = DecisionTree(\n",
    "            depth=self.depth + 1,\n",
    "            max_depth=self.max_depth,\n",
    "            classification=self.classification,\n",
    "        )\n",
    "        self.right = DecisionTree(\n",
    "            depth=self.depth + 1,\n",
    "            max_depth=self.max_depth,\n",
    "            classification=self.classification,\n",
    "        )\n",
    "\n",
    "        self.left.fit(X[best_left_mask], y[best_left_mask])\n",
    "        self.right.fit(X[best_right_mask], y[best_right_mask])\n",
    "\n",
    "    def _find_best_split(self, X, y, criterion_fn):\n",
    "        num_features = X.shape[1]\n",
    "        best_score = float(\"inf\")\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_left_mask = None\n",
    "        best_right_mask = None\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            thresholds = torch.unique(X[:, feature])\n",
    "\n",
    "            for ts in thresholds:\n",
    "                left_mask = X[:, feature] <= ts\n",
    "                right_mask = X[:, feature] > ts\n",
    "\n",
    "                if not left_mask.any() or not right_mask.any():\n",
    "                    continue\n",
    "\n",
    "                y_left = y[left_mask]\n",
    "                y_right = y[right_mask]\n",
    "\n",
    "                score = criterion_fn(y_left, y_right)\n",
    "\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_feature = feature\n",
    "                    best_threshold = ts.item()\n",
    "                    best_left_mask = left_mask\n",
    "                    best_right_mask = right_mask\n",
    "\n",
    "        return best_feature, best_threshold, best_left_mask, best_right_mask\n",
    "\n",
    "    def _get_prediction_value(self, y):\n",
    "        if self.classification:\n",
    "            return y.mode()[0].item()\n",
    "        return y.float().mean().item()\n",
    "\n",
    "    @staticmethod\n",
    "    def _gini_impurity(group):\n",
    "        if group.numel() == 0:\n",
    "            return 0.0\n",
    "        _, counts = torch.unique(group, return_counts=True)\n",
    "        probs = counts.float() / counts.sum()\n",
    "        return 1.0 - torch.sum(probs ** 2).item()\n",
    "\n",
    "    def _gini(self, y_left, y_right):\n",
    "        total_samples = y_left.numel() + y_right.numel()\n",
    "        gini_left = self._gini_impurity(y_left)\n",
    "        gini_right = self._gini_impurity(y_right)\n",
    "        return (\n",
    "            (y_left.numel() / total_samples) * gini_left\n",
    "            + (y_right.numel() / total_samples) * gini_right\n",
    "        )\n",
    "\n",
    "    def _mse(self, y_left, y_right):\n",
    "        total_samples = y_left.numel() + y_right.numel()\n",
    "        if total_samples == 0:\n",
    "            return 0.0\n",
    "\n",
    "        y_left_f = y_left.float()\n",
    "        y_right_f = y_right.float()\n",
    "\n",
    "        mse_left = (y_left_f - y_left_f.mean()).pow(2).mean().item()\n",
    "        mse_right = (y_right_f - y_right_f.mean()).pow(2).mean().item()\n",
    "\n",
    "        return (\n",
    "            (y_left.numel() / total_samples) * mse_left\n",
    "            + (y_right.numel() / total_samples) * mse_right\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05047539",
   "metadata": {},
   "source": [
    "## Random Forest implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30488c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators: int = 100,\n",
    "        max_depth: int = None,\n",
    "        max_features = None,\n",
    "        bootstrap: bool = True,\n",
    "        classification: bool = True,\n",
    "        random_state: int = None,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.classification = classification\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.features_per_tree = []\n",
    "\n",
    "    def _get_n_sub_features(self, n_features: int) -> int:\n",
    "        if self.max_features is None:\n",
    "            if self.classification:\n",
    "                k = int(math.sqrt(n_features))\n",
    "            else:\n",
    "                k = n_features\n",
    "        elif isinstance(self.max_features, float):\n",
    "            k = int(self.max_features * n_features)\n",
    "        else:\n",
    "            k = int(self.max_features)\n",
    "        k = max(1, k)\n",
    "        k = min(n_features, k)\n",
    "        return k\n",
    "\n",
    "    def fit(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        if self.random_state is not None:\n",
    "            torch.manual_seed(self.random_state)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        n_sub_features = self._get_n_sub_features(n_features)\n",
    "\n",
    "        self.trees = []\n",
    "        self.features_per_tree = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                indices = torch.randint(0, n_samples, (n_samples,))\n",
    "            else:\n",
    "                indices = torch.randperm(n_samples)\n",
    "\n",
    "            X_sample = X[indices]\n",
    "            y_sample = y[indices]\n",
    "\n",
    "            feature_indices = torch.randperm(n_features)[:n_sub_features]\n",
    "            X_sample_sub = X_sample[:, feature_indices]\n",
    "\n",
    "            tree = DecisionTree(\n",
    "                max_depth=self.max_depth,\n",
    "                classification=self.classification,\n",
    "            )\n",
    "            tree.fit(X_sample_sub, y_sample)\n",
    "\n",
    "            self.trees.append(tree)\n",
    "            self.features_per_tree.append(feature_indices)\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        if len(self.trees) == 0:\n",
    "            raise RuntimeError(\"RandomForest has not been fitted yet.\")\n",
    "\n",
    "        all_preds = []\n",
    "        for tree, feature_indices in zip(self.trees, self.features_per_tree):\n",
    "            X_sub = X[:, feature_indices]\n",
    "            preds = tree.predict(X_sub)\n",
    "            all_preds.append(preds)\n",
    "\n",
    "        preds_stack = torch.stack(all_preds, dim=0)\n",
    "\n",
    "        if self.classification:\n",
    "            values, _ = torch.mode(preds_stack, dim=0)\n",
    "            return values\n",
    "\n",
    "        return preds_stack.float().mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a61d4",
   "metadata": {},
   "source": [
    "## Gradient Boosting implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9493e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators: int = 100,\n",
    "        learning_rate: float = 0.1,\n",
    "        max_depth: int = 3,\n",
    "        classification: bool = True,\n",
    "        random_state: int | None = None,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.classification = classification\n",
    "        self.random_state = random_state\n",
    "        self.trees = None\n",
    "        self.init_prediction = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def fit(self, X: torch.Tensor, y: torch.Tensor):\n",
    "        if self.random_state is not None:\n",
    "            torch.manual_seed(self.random_state)\n",
    "\n",
    "        self.trees = None\n",
    "        self.init_prediction = None\n",
    "        self.num_classes = None\n",
    "\n",
    "        if not self.classification:\n",
    "            y_float = y.float()\n",
    "            self.num_classes = 1\n",
    "            self.init_prediction = y_float.mean().item()\n",
    "            F_vals = torch.full_like(y_float, self.init_prediction, dtype=torch.float32)\n",
    "            self.trees = []\n",
    "            for _ in range(self.n_estimators):\n",
    "                residuals = y_float - F_vals\n",
    "                tree = DecisionTree(\n",
    "                    max_depth=self.max_depth,\n",
    "                    classification=False,\n",
    "                )\n",
    "                tree.fit(X, residuals)\n",
    "                update = tree.predict(X).float()\n",
    "                F_vals = F_vals + self.learning_rate * update\n",
    "                self.trees.append(tree)\n",
    "            return\n",
    "\n",
    "        y_long = y.long()\n",
    "        unique = torch.unique(y_long)\n",
    "        self.num_classes = int(unique.numel())\n",
    "\n",
    "        if self.num_classes == 1:\n",
    "            self.init_prediction = unique[0].item()\n",
    "            self.trees = []\n",
    "            return\n",
    "\n",
    "        if self.num_classes == 2:\n",
    "            y_float = y_long.float()\n",
    "            p = y_float.mean()\n",
    "            eps = 1e-6\n",
    "            p = torch.clamp(p, eps, 1 - eps)\n",
    "            self.init_prediction = torch.log(p / (1 - p)).item()\n",
    "            F_vals = torch.full_like(y_float, self.init_prediction, dtype=torch.float32)\n",
    "            self.trees = []\n",
    "            for _ in range(self.n_estimators):\n",
    "                p_hat = torch.sigmoid(F_vals)\n",
    "                residuals = y_float - p_hat\n",
    "                tree = DecisionTree(\n",
    "                    max_depth=self.max_depth,\n",
    "                    classification=False,\n",
    "                )\n",
    "                tree.fit(X, residuals)\n",
    "                update = tree.predict(X).float()\n",
    "                F_vals = F_vals + self.learning_rate * update\n",
    "                self.trees.append(tree)\n",
    "            return\n",
    "\n",
    "        num_samples = y_long.shape[0]\n",
    "        num_classes = self.num_classes\n",
    "        y_one_hot = torch.zeros(num_samples, num_classes, dtype=torch.float32)\n",
    "        indices = torch.arange(num_samples)\n",
    "        y_one_hot[indices, y_long] = 1.0\n",
    "        scores = torch.zeros(num_samples, num_classes, dtype=torch.float32)\n",
    "        self.init_prediction = 0.0\n",
    "        self.trees = [[None for _ in range(self.n_estimators)] for _ in range(num_classes)]\n",
    "        for m in range(self.n_estimators):\n",
    "            probs = torch.softmax(scores, dim=1)\n",
    "            residuals = y_one_hot - probs\n",
    "            for k in range(num_classes):\n",
    "                tree = DecisionTree(\n",
    "                    max_depth=self.max_depth,\n",
    "                    classification=False,\n",
    "                )\n",
    "                tree.fit(X, residuals[:, k])\n",
    "                update = tree.predict(X).float()\n",
    "                scores[:, k] = scores[:, k] + self.learning_rate * update\n",
    "                self.trees[k][m] = tree\n",
    "\n",
    "    def _raw_predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.classification:\n",
    "            if self.trees is None or len(self.trees) == 0:\n",
    "                raise RuntimeError(\"GradientBoosting has not been fitted yet.\")\n",
    "            num_samples = X.shape[0]\n",
    "            F_vals = torch.full((num_samples,), self.init_prediction, dtype=torch.float32)\n",
    "            for tree in self.trees:\n",
    "                F_vals = F_vals + self.learning_rate * tree.predict(X).float()\n",
    "            return F_vals\n",
    "\n",
    "        if self.num_classes is None:\n",
    "            raise RuntimeError(\"GradientBoosting has not been fitted yet.\")\n",
    "\n",
    "        if self.num_classes == 1:\n",
    "            num_samples = X.shape[0]\n",
    "            return torch.full((num_samples,), float(self.init_prediction), dtype=torch.float32)\n",
    "\n",
    "        if self.num_classes == 2:\n",
    "            if self.trees is None or len(self.trees) == 0:\n",
    "                raise RuntimeError(\"GradientBoosting has not been fitted yet.\")\n",
    "            num_samples = X.shape[0]\n",
    "            F_vals = torch.full((num_samples,), self.init_prediction, dtype=torch.float32)\n",
    "            for tree in self.trees:\n",
    "                F_vals = F_vals + self.learning_rate * tree.predict(X).float()\n",
    "            return F_vals\n",
    "\n",
    "        num_samples = X.shape[0]\n",
    "        num_classes = self.num_classes\n",
    "        scores = torch.zeros(num_samples, num_classes, dtype=torch.float32)\n",
    "        for m in range(self.n_estimators):\n",
    "            for k in range(num_classes):\n",
    "                tree = self.trees[k][m]\n",
    "                update = tree.predict(X).float()\n",
    "                scores[:, k] = scores[:, k] + self.learning_rate * update\n",
    "        return scores\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        outputs = self._raw_predict(X)\n",
    "        if not self.classification:\n",
    "            return outputs\n",
    "        if self.num_classes == 1:\n",
    "            num_samples = outputs.shape[0]\n",
    "            return torch.full((num_samples,), int(self.init_prediction), dtype=torch.long)\n",
    "        if self.num_classes == 2:\n",
    "            proba_pos = torch.sigmoid(outputs)\n",
    "            return (proba_pos >= 0.5).long()\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        return torch.argmax(probs, dim=1)\n",
    "\n",
    "    def predict_proba(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.classification:\n",
    "            raise RuntimeError(\"predict_proba is only available for classification.\")\n",
    "        outputs = self._raw_predict(X)\n",
    "        if self.num_classes == 1:\n",
    "            num_samples = outputs.shape[0]\n",
    "            return torch.ones(num_samples, 1, dtype=torch.float32)\n",
    "        if self.num_classes == 2:\n",
    "            proba_pos = torch.sigmoid(outputs)\n",
    "            proba_neg = 1.0 - proba_pos\n",
    "            return torch.stack([proba_neg, proba_pos], dim=1)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d43ca8",
   "metadata": {},
   "source": [
    "## Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8774869e-1ca4-420e-801c-97df35f59c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "def get_regression_metrics(y_pred, y_true) -> None:\n",
    "    for m in [r2_score, mean_absolute_error, mean_absolute_percentage_error]:\n",
    "        print(f'Metric {m.__name__}')\n",
    "        print(f'Result {m(y_pred, y_true)}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46026122-74b6-46da-9715-a3c20526790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DT\n",
      "Metric r2_score\n",
      "Result -1.7970409393310547\n",
      "\n",
      "Metric mean_absolute_error\n",
      "Result 686.2468872070312\n",
      "\n",
      "Metric mean_absolute_percentage_error\n",
      "Result 0.6829274892807007\n",
      "\n",
      "Training RF\n",
      "Metric r2_score\n",
      "Result -1.3947644233703613\n",
      "\n",
      "Metric mean_absolute_error\n",
      "Result 658.37158203125\n",
      "\n",
      "Metric mean_absolute_percentage_error\n",
      "Result 0.6617386937141418\n",
      "\n",
      "Training GB\n",
      "Metric r2_score\n",
      "Result -2.0063259601593018\n",
      "\n",
      "Metric mean_absolute_error\n",
      "Result 668.3765869140625\n",
      "\n",
      "Metric mean_absolute_percentage_error\n",
      "Result 0.65778648853302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"london_merged.csv\")\n",
    "data.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "X, y = data.drop(columns=['cnt']).values, data.cnt.values\n",
    "\n",
    "X_train_np_reg, X_test_np_reg, y_train_np_reg, y_test_np_reg = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.2\n",
    ")\n",
    "\n",
    "X_train_reg = torch.tensor(X_train_np_reg, dtype=torch.float32)\n",
    "X_test_reg = torch.tensor(X_test_np_reg, dtype=torch.float32)\n",
    "y_train_reg = torch.tensor(y_train_np_reg, dtype=torch.float32)\n",
    "y_test_reg = torch.tensor(y_test_np_reg, dtype=torch.float32)\\\n",
    "\n",
    "print(\"Training DT\")\n",
    "\n",
    "dt_reg = DecisionTree(max_depth=4, classification=False)\n",
    "dt_reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_dt_reg = dt_reg.predict(X_test_reg)\n",
    "\n",
    "get_regression_metrics(y_pred_dt_reg, y_test_np_reg)\n",
    "\n",
    "print(\"Training RF\")\n",
    "\n",
    "rf_reg = RandomForest(\n",
    "    n_estimators=20,\n",
    "    max_depth=6,\n",
    "    max_features=None,\n",
    "    bootstrap=True,\n",
    "    classification=False,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_rf_reg = rf_reg.predict(X_test_reg)\n",
    "\n",
    "get_regression_metrics(y_pred_rf_reg, y_test_np_reg)\n",
    "\n",
    "print(\"Training GB\")\n",
    "\n",
    "gb_reg = GradientBoosting(\n",
    "    n_estimators=30,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    classification=False,\n",
    "    random_state=42,\n",
    ")\n",
    "gb_reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_gb_reg = gb_reg.predict(X_test_reg)\n",
    "\n",
    "get_regression_metrics(y_pred_gb_reg, y_test_np_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1e63c",
   "metadata": {},
   "source": [
    "## Binary classification task and model comparison (DT, RF, GB)\n",
    "\n",
    "We restrict CIFAR-10 to classes 0 and 1 to use Gradient Boosting for binary classification and compare models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdde0811-f480-4b2a-8091-2f63a04160e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "def get_classification_metrics(y_pred, y_true) -> None:\n",
    "    for m in [f1_score, recall_score, precision_score]:\n",
    "        print(f'Metric {m.__name__}')\n",
    "        print(f'Result {m(y_pred, y_true, average='weighted')}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ab127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric f1_score\n",
      "Result 0.25184079174073193\n",
      "\n",
      "Metric recall_score\n",
      "Result 0.2317\n",
      "\n",
      "Metric precision_score\n",
      "Result 0.3291374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"cifar-10-batches-py\"\n",
    "X_train_flat, y_train, X_test_flat, y_test = load_cifar10_with_maxpool(base_dir, pool_times=2)\n",
    "\n",
    "n_train = 10000\n",
    "perm = torch.randperm(X_train_flat.size(0))[:n_train]\n",
    "X_train_small = X_train_flat[perm]\n",
    "y_train_small = y_train[perm]\n",
    "\n",
    "dt_mc = DecisionTree(max_depth=4, classification=True)\n",
    "dt_mc.fit(X_train_small, y_train_small)\n",
    "y_pred_dt_mc = dt_mc.predict(X_test_flat)\n",
    "\n",
    "get_classification_metrics(y_pred_dt_mc, y_test)\n",
    "\n",
    "rf_mc = RandomForest(\n",
    "    n_estimators=20,\n",
    "    max_depth=6,\n",
    "    max_features=None,\n",
    "    bootstrap=True,\n",
    "    classification=True,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_mc.fit(X_train_small, y_train_small)\n",
    "y_pred_rf_mc = rf_mc.predict(X_test_flat)\n",
    "\n",
    "get_classification_metrics(y_pred_rf_mc, y_test)\n",
    "\n",
    "gb_mc = GradientBoosting(\n",
    "    n_estimators=20,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    classification=True,\n",
    "    random_state=42,\n",
    ")\n",
    "gb_mc.fit(X_train_small, y_train_small)\n",
    "y_pred_gb_mc = gb_mc.predict(X_test_flat)\n",
    "\n",
    "get_classification_metrics(y_pred_gb_mc, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7991d79-5fcc-4404-9799-344326026747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870629cf-1234-41eb-93ad-f2a29cc543ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700ad3a-1c90-45d2-95ee-3397fbd8d188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ais",
   "language": "python",
   "name": "ais"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
